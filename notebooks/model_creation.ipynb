{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, recall_score, precision_score, classification_report\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "import sqlite3 as sql\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "url = \"https://raw.githubusercontent.com/eserinanarslan/probability_prediction/main/data/dataset.csv?token=AOT2MQMPSJPFDLZ6CAQ4KILARVTBY\"\n",
    "data = pd.read_csv(url, delimiter=\";\")\n",
    "df = data.copy()\n",
    "df = reduce_mem_usage(df)\n",
    "df.to_excel(\"data.xlsx\", index=False)\n",
    "\"\"\"\n",
    "data = pd.read_excel(\"data.xlsx\")\n",
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99976, 43)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99976 entries, 0 to 99975\n",
      "Data columns (total 43 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   uuid                                 99976 non-null  object \n",
      " 1   default                              89976 non-null  float64\n",
      " 2   account_amount_added_12_24m          99976 non-null  int64  \n",
      " 3   account_days_in_dc_12_24m            88140 non-null  float64\n",
      " 4   account_days_in_rem_12_24m           88140 non-null  float64\n",
      " 5   account_days_in_term_12_24m          88140 non-null  float64\n",
      " 6   account_incoming_debt_vs_paid_0_24m  40661 non-null  float64\n",
      " 7   account_status                       45603 non-null  float64\n",
      " 8   account_worst_status_0_3m            45603 non-null  float64\n",
      " 9   account_worst_status_12_24m          33215 non-null  float64\n",
      " 10  account_worst_status_3_6m            42274 non-null  float64\n",
      " 11  account_worst_status_6_12m           39626 non-null  float64\n",
      " 12  age                                  99976 non-null  int64  \n",
      " 13  avg_payment_span_0_12m               76140 non-null  float64\n",
      " 14  avg_payment_span_0_3m                50671 non-null  float64\n",
      " 15  merchant_category                    99976 non-null  object \n",
      " 16  merchant_group                       99976 non-null  object \n",
      " 17  has_paid                             99976 non-null  bool   \n",
      " 18  max_paid_inv_0_12m                   99976 non-null  int64  \n",
      " 19  max_paid_inv_0_24m                   99976 non-null  int64  \n",
      " 20  name_in_email                        99976 non-null  object \n",
      " 21  num_active_div_by_paid_inv_0_12m     77037 non-null  float64\n",
      " 22  num_active_inv                       99976 non-null  int64  \n",
      " 23  num_arch_dc_0_12m                    99976 non-null  int64  \n",
      " 24  num_arch_dc_12_24m                   99976 non-null  int64  \n",
      " 25  num_arch_ok_0_12m                    99976 non-null  int64  \n",
      " 26  num_arch_ok_12_24m                   99976 non-null  int64  \n",
      " 27  num_arch_rem_0_12m                   99976 non-null  int64  \n",
      " 28  num_arch_written_off_0_12m           81898 non-null  float64\n",
      " 29  num_arch_written_off_12_24m          81898 non-null  float64\n",
      " 30  num_unpaid_bills                     99976 non-null  int64  \n",
      " 31  status_last_archived_0_24m           99976 non-null  int64  \n",
      " 32  status_2nd_last_archived_0_24m       99976 non-null  int64  \n",
      " 33  status_3rd_last_archived_0_24m       99976 non-null  int64  \n",
      " 34  status_max_archived_0_6_months       99976 non-null  int64  \n",
      " 35  status_max_archived_0_12_months      99976 non-null  int64  \n",
      " 36  status_max_archived_0_24_months      99976 non-null  int64  \n",
      " 37  recovery_debt                        99976 non-null  int64  \n",
      " 38  sum_capital_paid_account_0_12m       99976 non-null  int64  \n",
      " 39  sum_capital_paid_account_12_24m      99976 non-null  int64  \n",
      " 40  sum_paid_inv_0_12m                   99976 non-null  int64  \n",
      " 41  time_hours                           99976 non-null  float64\n",
      " 42  worst_status_active_inv              30461 non-null  float64\n",
      "dtypes: bool(1), float64(17), int64(21), object(4)\n",
      "memory usage: 32.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(\"no_match\", np.nan, inplace=True)\n",
    "df[\"has_paid\"].replace([True, False], [1,0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor col in df.select_dtypes(exclude=\"object\").columns.to_list():\\n    plt.figure(figsize=(15,8))\\n    ax = df[col].hist(density=True, stacked=True, color=\\'teal\\')\\n    df[col].plot(kind=\\'density\\', color=\\'teal\\')\\n    ax.set(xlabel=col)\\n    print(\"\\n\\n\")\\n    print(\"-\"*len(col))\\n    print(col)\\n    print(\"-\"*len(col))\\n    print(\"\")\\n    print(f\"Descriptive Statistics for {col}:\")\\n    print(\"-\"*(len(col) + 28))\\n    print(\"\")\\n    print(df[col].describe())\\n    print(\"\\n\")\\n    plt.grid()\\n    plt.show()\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for col in df.select_dtypes(exclude=\"object\").columns.to_list():\n",
    "    plt.figure(figsize=(15,8))\n",
    "    ax = df[col].hist(density=True, stacked=True, color='teal')\n",
    "    df[col].plot(kind='density', color='teal')\n",
    "    ax.set(xlabel=col)\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"-\"*len(col))\n",
    "    print(col)\n",
    "    print(\"-\"*len(col))\n",
    "    print(\"\")\n",
    "    print(f\"Descriptive Statistics for {col}:\")\n",
    "    print(\"-\"*(len(col) + 28))\n",
    "    print(\"\")\n",
    "    print(df[col].describe())\n",
    "    print(\"\\n\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bar Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncols_for_bar_plot = df.nunique().sort_values(ascending=False)[23:].index.to_list()\\nfor col in cols_for_bar_plot:\\n    print(\"-\"*len(col))\\n    print(col)\\n    print(\"-\"*len(col))\\n    print(\"\")\\n    print(f\"Unique values of \\'{col}\\':\")\\n    print(\"-\"*(20+len(col)))\\n    print(df[col].value_counts())\\n    print(\"\\n\")\\n    plt.figure(figsize=(20,10))\\n    sns.countplot(x=col, data=df, palette=\\'Set2\\')\\n    plt.grid()\\n    plt.show()\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "cols_for_bar_plot = df.nunique().sort_values(ascending=False)[23:].index.to_list()\n",
    "for col in cols_for_bar_plot:\n",
    "    print(\"-\"*len(col))\n",
    "    print(col)\n",
    "    print(\"-\"*len(col))\n",
    "    print(\"\")\n",
    "    print(f\"Unique values of '{col}':\")\n",
    "    print(\"-\"*(20+len(col)))\n",
    "    print(df[col].value_counts())\n",
    "    print(\"\\n\")\n",
    "    plt.figure(figsize=(20,10))\n",
    "    sns.countplot(x=col, data=df, palette='Set2')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.columns.to_list()[2:]+[df.columns.to_list()[0]]+[df.columns.to_list()[1]]]\n",
    "\n",
    "corr = df.corr()\n",
    "cr = corr.copy()\n",
    "top_corr_columns = []\n",
    "#Determine best correlate columns over 0.5\n",
    "top_corr_columns = cr.loc[:, 'default'][:-1]\n",
    "best_accurate_columns = top_corr_columns[abs(top_corr_columns) > 0.1].sort_values(ascending=False)\n",
    "len(best_accurate_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "avg_payment_span_0_12m              0.197384\n",
       "account_worst_status_6_12m          0.168975\n",
       "account_worst_status_0_3m           0.159137\n",
       "account_worst_status_12_24m         0.158235\n",
       "account_worst_status_3_6m           0.156539\n",
       "num_active_div_by_paid_inv_0_12m    0.137430\n",
       "account_status                      0.120683\n",
       "num_arch_dc_0_12m                   0.107296\n",
       "num_arch_dc_12_24m                  0.100891\n",
       "Name: default, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before_fillna = best_accurate_columns\n",
    "before_fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['account_worst_status_0_3m'].fillna(value=0, inplace=True) # Statüsü 1-2-3-4 olanlar. NA olanlara 0 atandı.\n",
    "df['account_worst_status_12_24m'].fillna(value=0, inplace=True) # Statüsü 1-2-3-4 olanlar. NA olanlara 0 atandı.\n",
    "df['account_worst_status_3_6m'].fillna(value=0, inplace=True) # Statüsü 1-2-3-4 olanlar. NA olanlara 0 atandı.\n",
    "df['account_worst_status_6_12m'].fillna(value=0, inplace=True) # Statüsü 1-2-3-4 olanlar. NA olanlara 0 atandı.\n",
    "df[\"account_status\"].fillna(value=0, inplace=True) # Statüsü 1-2-3-4 olanlar. NA olanlara 0 atandı.\n",
    "df[\"avg_payment_span_0_12m\"].fillna(value=df[\"avg_payment_span_0_12m\"].mean(), inplace=True) # Default ile korelasyonu 0 ile doldurduktan absolute 0.1'den yüksek çıkmıyor.\n",
    "df[\"num_active_div_by_paid_inv_0_12m\"].fillna(value=0, inplace=True) # Default ile korelasyonu 0 ile doldurduktan absolute 0.1'den yüksek çıkmıyor.\n",
    "df[\"account_days_in_dc_12_24m\"].fillna(value=0, inplace=True) #+\n",
    "df[\"account_days_in_rem_12_24m\"].fillna(value=0, inplace=True) #+\n",
    "df[\"account_days_in_term_12_24m\"].fillna(value=0, inplace=True) #+\n",
    "df[\"name_in_email\"].fillna(value=df[\"name_in_email\"].value_counts().index[0], inplace=True) #+\n",
    "df[\"num_arch_written_off_0_12m\"].fillna(value=0, inplace=True) #+\n",
    "df[\"num_arch_written_off_12_24m\"].fillna(value=0, inplace=True) #+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# account_worst_status_0_3m: Default ile korelasyonu absolute 0.1'den yüksek olmasına rağmen %50'den fazla missing value olduğu için silindi.\n",
    "# account_worst_status_3_6m: Default ile korelasyonu absolute 0.1'den yüksek olmasına rağmen %50'den fazla missing value olduğu için silindi.\n",
    "# account_worst_status_6_12m: Default ile korelasyonu absolute 0.1'den yüksek olmasına rağmen %50'den fazla missing value olduğu için silindi.\n",
    "# account_worst_status_12_24m: Default ile korelasyonu absolute 0.1'den yüksek olmasına rağmen %50'den fazla missing value olduğu için silindi.\n",
    "# account_status: Default ile korelasyonu absolute 0.1'den yüksek olmasına rağmen %50'den fazla missing value olduğu için silindi.\n",
    "\n",
    "# num_arch_written_off_0_12m: %99.9'u 0 değeri içerdiğin için atıldı.\n",
    "# num_arch_written_off_12_24m: %99.9'u 0 değeri içerdiğin için atıldı.\n",
    "\n",
    "cols_to_delete = [\"avg_payment_span_0_3m\", \"max_paid_inv_0_24m\", \"num_arch_ok_12_24m\",\n",
    "                 \"status_2nd_last_archived_0_24m\", \"status_3rd_last_archived_0_24m\",\n",
    "                  \"status_max_archived_0_24_months\", \"status_max_archived_0_12_months\",\n",
    "                 \"account_incoming_debt_vs_paid_0_24m\", \"worst_status_active_inv\", \n",
    "                  \"num_arch_written_off_0_12m\", \"num_arch_written_off_12_24m\"]\n",
    "df.drop(columns=cols_to_delete, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnull_cols = list(df.isnull().sum()[df.isnull().sum() > 0].index)\\nprint(\"Missing value içeren sütunlar aşağıdaki gibidir: \")\\nprint(\"-\"*len(\"Missing value içeren sütunlar aşağıdaki gibidir: \"))\\nprint(\"\\n\")\\nprint(null_cols)\\nprint(\"\\n\")\\nwhile True:\\n    try:\\n        col_to_plot = input(\"Missing value analizi için sütun ismi giriniz: \")\\n    except:\\n        pass\\n    if col_to_plot not in df.columns.to_list():\\n        continue\\n    else:\\n        break\\n\\nfor col in [col_to_plot]:\\n    print(\"\")\\n    print(\"-\"*(len(col)))\\n    print(f\"{col}:\")\\n    print(\"-\"*(len(col)))\\n    print(\"\")\\n    print(f\"{df[col].value_counts().sort_values(ascending=False)}\")\\n    print(\"\")\\n    print(\"-\"*(len(col)+len(\"Descriptive Statistics for  \")))\\n    print(f\"Descriptive Statistics for {col}:\")\\n    print(\"-\"*(len(col)+len(\"Descriptive Statistics for  \")))\\n    print(\"\")\\n    print(f\"{df[col].describe()}\")\\n    print(\"\\n\")\\n    print(f\\'Percent of missing {col} records is %.2f%%\\' %((df[col].isnull().sum()/df.shape[0])*100))\\n    print(\"=\"*180)\\n    print(\"\")\\n    if col in [\"account_incoming_debt_vs_paid_0_24m\", \"avg_payment_span_0_12m\", \"num_active_div_by_paid_inv_0_12m\"]:\\n        plt.figure(figsize=(15,8))\\n        ax = df[col].hist(density=True, stacked=True, color=\\'teal\\')\\n        df[col].plot(kind=\\'density\\', color=\\'teal\\')\\n        ax.set(xlabel=col)\\n        plt.grid()\\n        plt.show()\\n    else:\\n        plt.figure(figsize=(20,10))\\n        sns.countplot(x=col, data=df, palette=\\'Set2\\')\\n        plt.title(col+\" Count Plot\", fontdict={\"size\": 16})\\n        plt.xticks(rotation=90)\\n        plt.grid()\\n        plt.show()\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "null_cols = list(df.isnull().sum()[df.isnull().sum() > 0].index)\n",
    "print(\"Missing value içeren sütunlar aşağıdaki gibidir: \")\n",
    "print(\"-\"*len(\"Missing value içeren sütunlar aşağıdaki gibidir: \"))\n",
    "print(\"\\n\")\n",
    "print(null_cols)\n",
    "print(\"\\n\")\n",
    "while True:\n",
    "    try:\n",
    "        col_to_plot = input(\"Missing value analizi için sütun ismi giriniz: \")\n",
    "    except:\n",
    "        pass\n",
    "    if col_to_plot not in df.columns.to_list():\n",
    "        continue\n",
    "    else:\n",
    "        break\n",
    "\n",
    "for col in [col_to_plot]:\n",
    "    print(\"\")\n",
    "    print(\"-\"*(len(col)))\n",
    "    print(f\"{col}:\")\n",
    "    print(\"-\"*(len(col)))\n",
    "    print(\"\")\n",
    "    print(f\"{df[col].value_counts().sort_values(ascending=False)}\")\n",
    "    print(\"\")\n",
    "    print(\"-\"*(len(col)+len(\"Descriptive Statistics for  \")))\n",
    "    print(f\"Descriptive Statistics for {col}:\")\n",
    "    print(\"-\"*(len(col)+len(\"Descriptive Statistics for  \")))\n",
    "    print(\"\")\n",
    "    print(f\"{df[col].describe()}\")\n",
    "    print(\"\\n\")\n",
    "    print(f'Percent of missing {col} records is %.2f%%' %((df[col].isnull().sum()/df.shape[0])*100))\n",
    "    print(\"=\"*180)\n",
    "    print(\"\")\n",
    "    if col in [\"account_incoming_debt_vs_paid_0_24m\", \"avg_payment_span_0_12m\", \"num_active_div_by_paid_inv_0_12m\"]:\n",
    "        plt.figure(figsize=(15,8))\n",
    "        ax = df[col].hist(density=True, stacked=True, color='teal')\n",
    "        df[col].plot(kind='density', color='teal')\n",
    "        ax.set(xlabel=col)\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.figure(figsize=(20,10))\n",
    "        sns.countplot(x=col, data=df, palette='Set2')\n",
    "        plt.title(col+\" Count Plot\", fontdict={\"size\": 16})\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['account_amount_added_12_24m',\n",
       " 'account_days_in_dc_12_24m',\n",
       " 'account_days_in_rem_12_24m',\n",
       " 'account_days_in_term_12_24m',\n",
       " 'account_status',\n",
       " 'account_worst_status_0_3m',\n",
       " 'account_worst_status_12_24m',\n",
       " 'account_worst_status_3_6m',\n",
       " 'account_worst_status_6_12m',\n",
       " 'age',\n",
       " 'avg_payment_span_0_12m',\n",
       " 'default',\n",
       " 'has_paid',\n",
       " 'max_paid_inv_0_12m',\n",
       " 'merchant_category',\n",
       " 'merchant_group',\n",
       " 'name_in_email',\n",
       " 'num_active_div_by_paid_inv_0_12m',\n",
       " 'num_active_inv',\n",
       " 'num_arch_dc_0_12m',\n",
       " 'num_arch_dc_12_24m',\n",
       " 'num_arch_ok_0_12m',\n",
       " 'num_arch_rem_0_12m',\n",
       " 'num_unpaid_bills',\n",
       " 'recovery_debt',\n",
       " 'status_last_archived_0_24m',\n",
       " 'status_max_archived_0_6_months',\n",
       " 'sum_capital_paid_account_0_12m',\n",
       " 'sum_capital_paid_account_12_24m',\n",
       " 'sum_paid_inv_0_12m',\n",
       " 'time_hours',\n",
       " 'uuid']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(df.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncols_to_check = [col for col in df.columns.to_list() if \"sum_capital_paid_account_\" in col]\\n\\ndataframe = df[cols_to_check+[\"default\"]]\\nplt.figure(figsize=(16, 6))\\nheatmap = sns.heatmap(dataframe.corr(), vmin=-1, vmax=1, annot=True)\\nheatmap.set_title(\\'Correlation Heatmap\\', fontdict={\\'fontsize\\':12}, pad=12);\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "cols_to_check = [col for col in df.columns.to_list() if \"sum_capital_paid_account_\" in col]\n",
    "\n",
    "dataframe = df[cols_to_check+[\"default\"]]\n",
    "plt.figure(figsize=(16, 6))\n",
    "heatmap = sns.heatmap(dataframe.corr(), vmin=-1, vmax=1, annot=True)\n",
    "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12);\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = df.corr()\n",
    "cr = corr.copy()\n",
    "top_corr_columns = []\n",
    "#Determine best correlate columns over 0.5\n",
    "top_corr_columns = cr.loc[:, 'default'][:-1]\n",
    "best_accurate_columns = top_corr_columns[abs(top_corr_columns) > 0.05].sort_values(ascending=False)\n",
    "len(best_accurate_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "avg_payment_span_0_12m              0.142672\n",
       "num_arch_dc_0_12m                   0.107296\n",
       "num_arch_dc_12_24m                  0.100891\n",
       "account_worst_status_0_3m           0.097868\n",
       "num_active_div_by_paid_inv_0_12m    0.089509\n",
       "account_days_in_term_12_24m         0.084198\n",
       "account_days_in_rem_12_24m          0.083576\n",
       "account_worst_status_3_6m           0.080939\n",
       "account_worst_status_6_12m          0.080219\n",
       "account_status                      0.069771\n",
       "account_worst_status_12_24m         0.067244\n",
       "account_days_in_dc_12_24m           0.063395\n",
       "Name: default, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_fillna = best_accurate_columns\n",
    "after_fillna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibrated - SVM - Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  3.05 Mb (71.4% reduction)\n"
     ]
    }
   ],
   "source": [
    "df_prepared = pd.read_csv(\"../data/prepared_data.csv\")\n",
    "df_prepared = reduce_mem_usage(df_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restapi pickle'dan okuyacak. get yapıp uuid'nin resultlarını dönecek\n",
    "---\n",
    "## Calibrated'a birden fazla classifer koyabiliyor muyuz bir bak\n",
    "---\n",
    "## py dosyaısınınDockerize ile ayağa kalkmasını sağlayacaz.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prepared = pd.merge(df_prepared, df[[\"uuid\", \"age\", \"merchant_category\", \"merchant_group\", \"name_in_email\", \"has_paid\"]], how=\"left\", on=\"uuid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method : auto    - Running Time : 0:00:00.006948 - Number of bins : 97    - Head : [18.         18.85416667 19.70833333] - Tail : [98.29166667 99.14583333]\n",
      "Method : fd      - Running Time : 0:00:00.004017 - Number of bins : 97    - Head : [18.         18.85416667 19.70833333] - Tail : [98.29166667 99.14583333]\n",
      "Method : doane   - Running Time : 0:00:00.009970 - Number of bins : 26    - Head : [18.   21.28 24.56] - Tail : [93.44 96.72]\n",
      "Method : scott   - Running Time : 0:00:00.005010 - Number of bins : 85    - Head : [18.         18.97619048 19.95238095] - Tail : [98.04761905 99.02380952]\n",
      "Method : stone   - Running Time : 0:00:00.819834 - Number of bins : 317   - Head : [18.         18.25949367 18.51898734] - Tail : [99.48101266 99.74050633]\n",
      "Method : rice    - Running Time : 0:00:00.002994 - Number of bins : 94    - Head : [18.         18.88172043 19.76344086] - Tail : [98.23655914 99.11827957]\n",
      "Method : sturges - Running Time : 0:00:00.002995 - Number of bins : 19    - Head : [18.         22.55555556 27.11111111] - Tail : [90.88888889 95.44444444]\n",
      "Method : sqrt    - Running Time : 0:00:00.002955 - Number of bins : 318   - Head : [18.         18.25867508 18.51735016] - Tail : [99.48264984 99.74132492]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_payment_span_0_12m</th>\n",
       "      <th>num_arch_dc_0_12m</th>\n",
       "      <th>num_arch_dc_12_24m</th>\n",
       "      <th>account_worst_status_0_3m</th>\n",
       "      <th>num_active_div_by_paid_inv_0_12m</th>\n",
       "      <th>account_days_in_term_12_24m</th>\n",
       "      <th>account_days_in_rem_12_24m</th>\n",
       "      <th>account_worst_status_3_6m</th>\n",
       "      <th>account_worst_status_6_12m</th>\n",
       "      <th>account_status</th>\n",
       "      <th>account_worst_status_12_24m</th>\n",
       "      <th>account_days_in_dc_12_24m</th>\n",
       "      <th>uuid</th>\n",
       "      <th>default</th>\n",
       "      <th>age</th>\n",
       "      <th>merchant_category</th>\n",
       "      <th>merchant_group</th>\n",
       "      <th>name_in_email</th>\n",
       "      <th>has_paid</th>\n",
       "      <th>age_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.695312</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.153809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63f69b2c-8b1c-4740-b78d-52ed9a4515ac</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>Dietary supplements</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>F+L</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.828125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0e961183-8c15-4470-9a5e-07a1bd207661</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50</td>\n",
       "      <td>Books &amp; Magazines</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>F+L</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>d8edaae6-4368-44e0-941e-8328f203e64e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>Diversified entertainment</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>L1+F</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.687500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0095dfb6-a886-4e2a-b056-15ef45fdb0ef</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "      <td>Diversified entertainment</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>F1+L</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>c8f8b835-5647-4506-bf15-49105d8af30b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>Electronic equipment &amp; Related accessories</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>F+L</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99971</th>\n",
       "      <td>10.335938</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5c03bc63-ea65-4ffd-aa7b-95ea9a46db34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33</td>\n",
       "      <td>Electronic equipment &amp; Related accessories</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>F1+L</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99972</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>f8db22f4-9819-420c-abbc-9ddf1843176e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>Body &amp; Hair Care</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>F1+L</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973</th>\n",
       "      <td>17.968750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>b22e21ea-b1b2-4df3-b236-0ff6d5fdc0d8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "      <td>Jewelry &amp; Watches</td>\n",
       "      <td>Jewelry &amp; Accessories</td>\n",
       "      <td>Nick</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99974</th>\n",
       "      <td>17.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bafcab15-9898-479c-b729-c9dda7edb78f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>Decoration &amp; Art</td>\n",
       "      <td>Home &amp; Garden</td>\n",
       "      <td>Nick</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99975</th>\n",
       "      <td>34.656250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ac88f18c-96a6-49bc-9e9d-a780225914af</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>Dietary supplements</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>F1+L</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       avg_payment_span_0_12m  num_arch_dc_0_12m  num_arch_dc_12_24m  \\\n",
       "0                   12.695312                  0                   0   \n",
       "1                   25.828125                  0                   0   \n",
       "2                   20.000000                  0                   0   \n",
       "3                    4.687500                  0                   0   \n",
       "4                   13.000000                  0                   0   \n",
       "99971               10.335938                  0                   0   \n",
       "99972               36.000000                  0                   0   \n",
       "99973               17.968750                  0                   0   \n",
       "99974               17.500000                  0                   0   \n",
       "99975               34.656250                  0                   0   \n",
       "\n",
       "       account_worst_status_0_3m  num_active_div_by_paid_inv_0_12m  \\\n",
       "0                            1.0                          0.153809   \n",
       "1                            1.0                          0.000000   \n",
       "2                            0.0                          0.071411   \n",
       "3                            0.0                          0.031250   \n",
       "4                            0.0                          0.000000   \n",
       "99971                        1.0                          0.000000   \n",
       "99972                        1.0                          0.000000   \n",
       "99973                        2.0                          0.000000   \n",
       "99974                        2.0                          0.000000   \n",
       "99975                        1.0                          0.000000   \n",
       "\n",
       "       account_days_in_term_12_24m  account_days_in_rem_12_24m  \\\n",
       "0                              0.0                         0.0   \n",
       "1                              0.0                         0.0   \n",
       "2                              0.0                         0.0   \n",
       "3                              0.0                         0.0   \n",
       "4                              0.0                         0.0   \n",
       "99971                          0.0                         0.0   \n",
       "99972                          0.0                         0.0   \n",
       "99973                          0.0                        20.0   \n",
       "99974                          0.0                         0.0   \n",
       "99975                          0.0                         0.0   \n",
       "\n",
       "       account_worst_status_3_6m  account_worst_status_6_12m  account_status  \\\n",
       "0                            1.0                         0.0             1.0   \n",
       "1                            1.0                         1.0             1.0   \n",
       "2                            0.0                         0.0             0.0   \n",
       "3                            0.0                         0.0             0.0   \n",
       "4                            0.0                         0.0             0.0   \n",
       "99971                        0.0                         0.0             1.0   \n",
       "99972                        1.0                         1.0             1.0   \n",
       "99973                        1.0                         1.0             2.0   \n",
       "99974                        2.0                         2.0             1.0   \n",
       "99975                        1.0                         0.0             1.0   \n",
       "\n",
       "       account_worst_status_12_24m  account_days_in_dc_12_24m  \\\n",
       "0                              0.0                        0.0   \n",
       "1                              1.0                        0.0   \n",
       "2                              0.0                        0.0   \n",
       "3                              0.0                        0.0   \n",
       "4                              0.0                        0.0   \n",
       "99971                          0.0                        0.0   \n",
       "99972                          0.0                        0.0   \n",
       "99973                          2.0                        0.0   \n",
       "99974                          1.0                        0.0   \n",
       "99975                          0.0                        0.0   \n",
       "\n",
       "                                       uuid  default  age  \\\n",
       "0      63f69b2c-8b1c-4740-b78d-52ed9a4515ac      0.0   20   \n",
       "1      0e961183-8c15-4470-9a5e-07a1bd207661      0.0   50   \n",
       "2      d8edaae6-4368-44e0-941e-8328f203e64e      0.0   22   \n",
       "3      0095dfb6-a886-4e2a-b056-15ef45fdb0ef      0.0   36   \n",
       "4      c8f8b835-5647-4506-bf15-49105d8af30b      0.0   25   \n",
       "99971  5c03bc63-ea65-4ffd-aa7b-95ea9a46db34      NaN   33   \n",
       "99972  f8db22f4-9819-420c-abbc-9ddf1843176e      NaN   44   \n",
       "99973  b22e21ea-b1b2-4df3-b236-0ff6d5fdc0d8      NaN   24   \n",
       "99974  bafcab15-9898-479c-b729-c9dda7edb78f      NaN   31   \n",
       "99975  ac88f18c-96a6-49bc-9e9d-a780225914af      NaN   41   \n",
       "\n",
       "                                merchant_category         merchant_group  \\\n",
       "0                             Dietary supplements        Health & Beauty   \n",
       "1                               Books & Magazines          Entertainment   \n",
       "2                       Diversified entertainment          Entertainment   \n",
       "3                       Diversified entertainment          Entertainment   \n",
       "4      Electronic equipment & Related accessories            Electronics   \n",
       "99971  Electronic equipment & Related accessories            Electronics   \n",
       "99972                            Body & Hair Care        Health & Beauty   \n",
       "99973                           Jewelry & Watches  Jewelry & Accessories   \n",
       "99974                            Decoration & Art          Home & Garden   \n",
       "99975                         Dietary supplements        Health & Beauty   \n",
       "\n",
       "      name_in_email  has_paid  age_category  \n",
       "0               F+L         1             0  \n",
       "1               F+L         1             4  \n",
       "2              L1+F         1             0  \n",
       "3              F1+L         1             2  \n",
       "4               F+L         1             0  \n",
       "99971          F1+L         1             2  \n",
       "99972          F1+L         1             3  \n",
       "99973          Nick         1             0  \n",
       "99974          Nick         1             2  \n",
       "99975          F1+L         1             3  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins_methods = [ \"auto\", \"fd\", \"doane\", \"scott\", \"stone\", \"rice\", \"sturges\", \"sqrt\"]\n",
    "\n",
    "# https://stackoverflow.com/a/18364570\n",
    "def get_columns_bins(column_name):\n",
    "    all_bins = []\n",
    "  \n",
    "    for method in bins_methods:\n",
    "        start = datetime.now()\n",
    "        hist, bin_edges = np.histogram(column_name,bins=method)\n",
    "        all_bins.append(bin_edges)\n",
    "        print(\"Method : {:<7} - Running Time : {:<5} - Number of bins : {:<5} - Head : {} - Tail : {}\".format(method,str(datetime.now()-start), len(bin_edges), bin_edges[:3], bin_edges[-3:-1]))\n",
    "    return all_bins\n",
    "\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/a/18364570\n",
    "def get_clustering_bins(s, quantile=0.3, n_samples=None):\n",
    "    \n",
    "    series = s.dropna().values.reshape(-1, 1)\n",
    "    \n",
    "    bandwidth = estimate_bandwidth(series, quantile=quantile, n_samples=n_samples)\n",
    "    clustering = MeanShift(bandwidth=bandwidth, bin_seeding=True).fit(series)\n",
    "\n",
    "    d = pd.DataFrame(columns=['data_column', 'label_column'])\n",
    "\n",
    "    d['data_column'] = series.reshape(-1)\n",
    "    d['label_column'] = clustering.labels_\n",
    "    \n",
    "    sorted_vals = d.groupby('label_column')['data_column'].max().sort_values().values\n",
    "    bins = np.insert(sorted_vals, [0] , [series.min()-1])\n",
    "    bins[-1] = bins[-1] + 1\n",
    "    \n",
    "    return bins, range(bins.size-1)\n",
    "\n",
    "\n",
    "age_bins = []\n",
    "age_bins = get_columns_bins(df_prepared.age)\n",
    "\n",
    "\n",
    "age_bin,label = get_clustering_bins(pd.Series(age_bins[0]), quantile=0.2, n_samples=10)\n",
    "df_prepared.age.hist(bins=age_bin)\n",
    "age_bin\n",
    "\n",
    "\n",
    "len(age_bin) , df_prepared.age.value_counts(bins=age_bin)\n",
    "df_prepared['age_category'] = pd.cut(df_prepared.age, age_bin).cat.codes\n",
    "df_prepared.head(5).append(df_prepared.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_prepared.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant_cat_others = list(df_prepared[\"merchant_category\"].value_counts()[df_prepared[\"merchant_category\"].value_counts() < 800].index)\n",
    "df_prepared[\"merchant_category\"] = df_prepared[\"merchant_category\"].apply(lambda x: \"Other\" if x in merchant_cat_others else x)\n",
    "\n",
    "\n",
    "merchant_dict = {'Entertainment':1, 'Leisure, Sport & Hobby':2, 'Clothing & Shoes':4, 'Health & Beauty':6, 'Jewelry & Accessories':7, \n",
    "                 'Food & Beverage':9, 'Children Products':11, 'Home & Garden':13, 'Electronics':15, 'Automotive Products':17, \n",
    "                 'Intangible products':19, 'Erotic Materials':20}\n",
    "\n",
    "df_prepared[\"merchant_group\"] = df_prepared[\"merchant_group\"].replace(merchant_dict.keys(), merchant_dict.values())\n",
    "df_prepared = pd.concat([df_prepared, pd.get_dummies(df_prepared[\"name_in_email\"],prefix=\"in_email_\")], axis=1)\n",
    "df_prepared.drop(columns=[\"name_in_email\", \"age\"], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "le_merchant_category = LabelEncoder()\n",
    "df_prepared[\"merchant_category\"] = le_merchant_category.fit_transform(df_prepared[\"merchant_category\"])\n",
    "\n",
    "#df_prepared = df_prepared[df_prepared.columns.to_list()[-16:] + df_prepared.columns.to_list()[:-16]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance the data using SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_default_null = df_prepared[pd.isnull(df_prepared[\"default\"])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of oversampled data is  124204\n",
      "Number of no subscription in oversampled data 62102\n",
      "Number of subscription 62102\n",
      "Proportion of no subscription data in oversampled data is  0.5\n",
      "Proportion of subscription data in oversampled data is  0.5\n"
     ]
    }
   ],
   "source": [
    "df_analyze = df_prepared.dropna().reset_index(drop=True)\n",
    "\n",
    "X = df_analyze.drop(columns=[\"uuid\", \"default\"])\n",
    "y = df_analyze[\"default\"]\n",
    "os = SMOTE(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "columns = X_train.columns\n",
    "os_data_X,os_data_y=os.fit_sample(X_train, y_train)\n",
    "os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
    "os_data_y= pd.DataFrame(data=os_data_y,columns=['default'])\n",
    "# we can Check the numbers of our data\n",
    "print(\"Length of oversampled data is \",len(os_data_X))\n",
    "print(\"Number of no subscription in oversampled data\",len(os_data_y[os_data_y['default']==0]))\n",
    "print(\"Number of subscription\",len(os_data_y[os_data_y['default']==1]))\n",
    "print(\"Proportion of no subscription data in oversampled data is \",len(os_data_y[os_data_y['default']==0])/len(os_data_X))\n",
    "print(\"Proportion of subscription data in oversampled data is \",len(os_data_y[os_data_y['default']==1])/len(os_data_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=4)]: Done  80 out of  80 | elapsed: 17.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 8, 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 700}\n",
      "\n",
      "Çalışma süresi: 00:20:00.55\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "n_estimators = [200, 700]\n",
    "max_depth = [5, 8]\n",
    "min_samples_split = [10, 100]\n",
    "min_samples_leaf = [5, 10]\n",
    "hyper_random = {\"n_estimators\":n_estimators,\n",
    "              \"max_depth\":max_depth,\n",
    "              \"min_samples_split\":min_samples_split,\n",
    "              \"min_samples_leaf\":min_samples_leaf}\n",
    "\n",
    "clf_rf_tuned = GridSearchCV(RandomForestClassifier(), hyper_random, \n",
    "                            cv = 5, verbose = 1, \n",
    "                            n_jobs = 4)\n",
    "clf_rf_tuned.fit(os_data_X, os_data_y)\n",
    "best_params_random = clf_rf_tuned.best_params_\n",
    "print(best_params_random)\n",
    "\n",
    "\n",
    "CV_clf_rf = RandomForestClassifier(max_depth=best_params_random[\"max_depth\"],\n",
    "                                   min_samples_leaf=best_params_random[\"min_samples_leaf\"],\n",
    "                                   min_samples_split=best_params_random[\"min_samples_split\"],\n",
    "                                   n_estimators= best_params_random[\"n_estimators\"])\n",
    "CV_clf_rf.fit(os_data_X, os_data_y)\n",
    "y_test_predict_proba_random = CV_clf_rf.predict_proba(X_test)[:, 1]\n",
    "yhat_random = CV_clf_rf.predict(X_test)\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(y_test, y_test_predict_proba_random, n_bins=10)\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "hours, rem = divmod(end-start, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print(\"\\nÇalışma süresi: \"+\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Çalışma süresi: 00:09:43.44\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Create a corrected classifier.\n",
    "\n",
    "clf_sigmoid = CalibratedClassifierCV(CV_clf_rf, cv=10, method='sigmoid')\n",
    "clf_sigmoid.fit(os_data_X, os_data_y)\n",
    "y_test_predict_proba_random_calibrated = clf_sigmoid.predict_proba(X_test)[:, 1]\n",
    "yhat_calibrated_random = clf_sigmoid.predict(X_test)\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(y_test, y_test_predict_proba_random_calibrated, n_bins=10)\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "hours, rem = divmod(end-start, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print(\"\\nÇalışma süresi: \"+\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.89      0.94     26586\n",
      "         1.0       0.07      0.52      0.12       407\n",
      "\n",
      "    accuracy                           0.89     26993\n",
      "   macro avg       0.53      0.70      0.53     26993\n",
      "weighted avg       0.98      0.89      0.93     26993\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, yhat_random))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrated Random Forest Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.90      0.94     26586\n",
      "         1.0       0.07      0.51      0.12       407\n",
      "\n",
      "    accuracy                           0.89     26993\n",
      "   macro avg       0.53      0.71      0.53     26993\n",
      "weighted avg       0.98      0.89      0.93     26993\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, yhat_calibrated_random))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Çalışma süresi: 00:00:04.99\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# Uncalibrated\n",
    "clf_nb = GaussianNB()\n",
    "clf_nb.fit(os_data_X, os_data_y)\n",
    "y_test_predict_proba_nb = clf_nb.predict_proba(X_test)[:, 1]\n",
    "yhat_nb = clf_nb.predict(X_test)\n",
    "fraction_of_positives_nb, mean_predicted_value_nb = calibration_curve(y_test, y_test_predict_proba_nb, n_bins=10)\n",
    "\n",
    "#plt.plot(mean_predicted_value_nb, fraction_of_positives_nb, 's-', label='Uncalibrated')\n",
    "\n",
    "# Calibrated\n",
    "clf_sigmoid_nb = CalibratedClassifierCV(clf_nb, cv=10, method='isotonic')\n",
    "clf_sigmoid_nb.fit(os_data_X, os_data_y)\n",
    "y_test_predict_proba_nb_calib = clf_sigmoid_nb.predict_proba(X_test)[:, 1]\n",
    "yhat_calibrated_nb = clf_sigmoid_nb.predict(X_test)\n",
    "fraction_of_positives_nb_calib, mean_predicted_value_nb_calib = calibration_curve(y_test, y_test_predict_proba_nb_calib, n_bins=10)\n",
    "\n",
    "#plt.plot(mean_predicted_value_nb_calib, fraction_of_positives_nb_calib, 's-', color='red', label='Calibrated (Isotonic)')\n",
    "\n",
    "# Calibrated, Platt\n",
    "clf_sigmoid_nb_calib_sig = CalibratedClassifierCV(clf_nb, cv=10, method='sigmoid')\n",
    "clf_sigmoid_nb_calib_sig.fit(os_data_X, os_data_y)\n",
    "\n",
    "y_test_predict_proba_nb_calib_platt = clf_sigmoid_nb_calib_sig.predict_proba(X_test)[:, 1]\n",
    "yhat_calibrated_platt = clf_sigmoid_nb_calib_sig.predict(X_test)\n",
    "\n",
    "fraction_of_positives_nb_calib_platt, mean_predicted_value_nb_calib_platt = calibration_curve(y_test, y_test_predict_proba_nb_calib_platt, n_bins=10)\n",
    "#plt.plot(mean_predicted_value_nb_calib_platt, fraction_of_positives_nb_calib_platt, 's-', color='orange', label='Calibrated (Platt)')\n",
    "\n",
    "\n",
    "#plt.plot([0, 1], [0, 1], '--', color='gray')\n",
    "\n",
    "#sns.despine(left=True, bottom=True)\n",
    "#plt.gca().xaxis.set_ticks_position('none')\n",
    "#plt.gca().yaxis.set_ticks_position('none')\n",
    "#plt.gca().legend()\n",
    "#plt.title(\"$GaussianNB$ Sample Calibration Curve\", fontsize=20); pass\n",
    "\n",
    "end = time.time()\n",
    "hours, rem = divmod(end-start, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print(\"\\nÇalışma süresi: \"+\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.84      0.91     26586\n",
      "         1.0       0.05      0.50      0.08       407\n",
      "\n",
      "    accuracy                           0.84     26993\n",
      "   macro avg       0.52      0.67      0.50     26993\n",
      "weighted avg       0.98      0.84      0.90     26993\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, yhat_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrated Gaussian Naive Bayes Results (Isotonic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.71      0.83     26586\n",
      "         1.0       0.03      0.61      0.06       407\n",
      "\n",
      "    accuracy                           0.71     26993\n",
      "   macro avg       0.51      0.66      0.44     26993\n",
      "weighted avg       0.98      0.71      0.81     26993\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, yhat_calibrated_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrated Gaussian Naive Bayes Results (Sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.82      0.90     26586\n",
      "         1.0       0.04      0.53      0.08       407\n",
      "\n",
      "    accuracy                           0.82     26993\n",
      "   macro avg       0.52      0.67      0.49     26993\n",
      "weighted avg       0.98      0.82      0.89     26993\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, yhat_calibrated_platt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NULL Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_default_null_keep = df_default_null[[\"uuid\", \"default\"]]\n",
    "df_default_null.drop(columns=[\"uuid\", \"default\"], axis=1, inplace=True)\n",
    "\n",
    "# Random Forest\n",
    "y_predict_proba = CV_clf_rf.predict_proba(df_default_null)[:, 1]\n",
    "yhat_predict = CV_clf_rf.predict(df_default_null)\n",
    "\n",
    "# Calibrated Random Forest\n",
    "y_predict_proba_crf = clf_sigmoid.predict_proba(df_default_null)[:, 1]\n",
    "yhat_predict_crf = clf_sigmoid.predict(df_default_null)\n",
    "\n",
    "#NB\n",
    "\n",
    "y_predict_nb = clf_nb.predict_proba(df_default_null)[:, 1]\n",
    "yhat_predict_nb = clf_nb.predict(df_default_null)\n",
    "\n",
    "# Isotonic\n",
    "y_predict_nb_isotonic = clf_sigmoid_nb.predict_proba(df_default_null)[:, 1]\n",
    "yhat_predict_isotonic = clf_sigmoid_nb.predict(df_default_null)\n",
    "\n",
    "# Sigmoid\n",
    "y_predict_nb_sigmoid = clf_sigmoid_nb_calib_sig.predict_proba(df_default_null)[:, 1]\n",
    "yhat_predict_sigmoid = clf_sigmoid_nb_calib_sig.predict(df_default_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_df_rf_nb = pd.concat([df_default_null_keep, \n",
    "           pd.Series(y_predict_proba, name=\"Random Forest Probability\"),\n",
    "           pd.Series(y_predict_proba_crf, name=\"Calibrated Random Forest Probability\"),\n",
    "           pd.Series(y_predict_nb, name=\"Naive Bayes\"), \n",
    "           pd.Series(y_predict_nb_isotonic, name=\"Calibrated Naive Bayes (Isotonic)\"),\n",
    "           pd.Series(y_predict_nb_sigmoid, name=\"Calibrated Naive Bayes (Sigmoid)\")], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>default</th>\n",
       "      <th>Random Forest Probability</th>\n",
       "      <th>Calibrated Random Forest Probability</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>Calibrated Naive Bayes (Isotonic)</th>\n",
       "      <th>Calibrated Naive Bayes (Sigmoid)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6f6e6c6a-2081-4e6b-8eb3-4fd89b54b2d7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.207778</td>\n",
       "      <td>0.025884</td>\n",
       "      <td>1.723595e-16</td>\n",
       "      <td>0.078878</td>\n",
       "      <td>0.203904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f6f6d9f3-ef2b-4329-a388-c6a687f27e70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.227243</td>\n",
       "      <td>0.040080</td>\n",
       "      <td>1.198108e-10</td>\n",
       "      <td>0.078878</td>\n",
       "      <td>0.203904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e9c39869-1bc5-4375-b627-a2df70b445ea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.250519</td>\n",
       "      <td>0.038526</td>\n",
       "      <td>6.578015e-10</td>\n",
       "      <td>0.078878</td>\n",
       "      <td>0.203904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6beb88a3-9641-4381-beb6-c9a208664dd0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.133105</td>\n",
       "      <td>0.012570</td>\n",
       "      <td>7.194286e-01</td>\n",
       "      <td>0.715523</td>\n",
       "      <td>0.726395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bb89b735-72fe-42a4-ba06-d63be0f4ca36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.481870</td>\n",
       "      <td>0.463070</td>\n",
       "      <td>2.760891e-20</td>\n",
       "      <td>0.051489</td>\n",
       "      <td>0.203904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>5c03bc63-ea65-4ffd-aa7b-95ea9a46db34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.274077</td>\n",
       "      <td>0.057775</td>\n",
       "      <td>6.593509e-23</td>\n",
       "      <td>0.051489</td>\n",
       "      <td>0.203904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>f8db22f4-9819-420c-abbc-9ddf1843176e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.220784</td>\n",
       "      <td>0.040960</td>\n",
       "      <td>5.740623e-23</td>\n",
       "      <td>0.051489</td>\n",
       "      <td>0.203904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>b22e21ea-b1b2-4df3-b236-0ff6d5fdc0d8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.467393</td>\n",
       "      <td>0.347172</td>\n",
       "      <td>1.128895e-01</td>\n",
       "      <td>0.389422</td>\n",
       "      <td>0.270498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>bafcab15-9898-479c-b729-c9dda7edb78f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.507091</td>\n",
       "      <td>0.430070</td>\n",
       "      <td>1.450127e-01</td>\n",
       "      <td>0.405623</td>\n",
       "      <td>0.291641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>ac88f18c-96a6-49bc-9e9d-a780225914af</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.290860</td>\n",
       "      <td>0.088791</td>\n",
       "      <td>4.470030e-23</td>\n",
       "      <td>0.051489</td>\n",
       "      <td>0.203904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      uuid  default  \\\n",
       "0     6f6e6c6a-2081-4e6b-8eb3-4fd89b54b2d7      NaN   \n",
       "1     f6f6d9f3-ef2b-4329-a388-c6a687f27e70      NaN   \n",
       "2     e9c39869-1bc5-4375-b627-a2df70b445ea      NaN   \n",
       "3     6beb88a3-9641-4381-beb6-c9a208664dd0      NaN   \n",
       "4     bb89b735-72fe-42a4-ba06-d63be0f4ca36      NaN   \n",
       "...                                    ...      ...   \n",
       "9995  5c03bc63-ea65-4ffd-aa7b-95ea9a46db34      NaN   \n",
       "9996  f8db22f4-9819-420c-abbc-9ddf1843176e      NaN   \n",
       "9997  b22e21ea-b1b2-4df3-b236-0ff6d5fdc0d8      NaN   \n",
       "9998  bafcab15-9898-479c-b729-c9dda7edb78f      NaN   \n",
       "9999  ac88f18c-96a6-49bc-9e9d-a780225914af      NaN   \n",
       "\n",
       "      Random Forest Probability  Calibrated Random Forest Probability  \\\n",
       "0                      0.207778                              0.025884   \n",
       "1                      0.227243                              0.040080   \n",
       "2                      0.250519                              0.038526   \n",
       "3                      0.133105                              0.012570   \n",
       "4                      0.481870                              0.463070   \n",
       "...                         ...                                   ...   \n",
       "9995                   0.274077                              0.057775   \n",
       "9996                   0.220784                              0.040960   \n",
       "9997                   0.467393                              0.347172   \n",
       "9998                   0.507091                              0.430070   \n",
       "9999                   0.290860                              0.088791   \n",
       "\n",
       "       Naive Bayes  Calibrated Naive Bayes (Isotonic)  \\\n",
       "0     1.723595e-16                           0.078878   \n",
       "1     1.198108e-10                           0.078878   \n",
       "2     6.578015e-10                           0.078878   \n",
       "3     7.194286e-01                           0.715523   \n",
       "4     2.760891e-20                           0.051489   \n",
       "...            ...                                ...   \n",
       "9995  6.593509e-23                           0.051489   \n",
       "9996  5.740623e-23                           0.051489   \n",
       "9997  1.128895e-01                           0.389422   \n",
       "9998  1.450127e-01                           0.405623   \n",
       "9999  4.470030e-23                           0.051489   \n",
       "\n",
       "      Calibrated Naive Bayes (Sigmoid)  \n",
       "0                             0.203904  \n",
       "1                             0.203904  \n",
       "2                             0.203904  \n",
       "3                             0.726395  \n",
       "4                             0.203904  \n",
       "...                                ...  \n",
       "9995                          0.203904  \n",
       "9996                          0.203904  \n",
       "9997                          0.270498  \n",
       "9998                          0.291641  \n",
       "9999                          0.203904  \n",
       "\n",
       "[10000 rows x 7 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_df_rf_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_analyze_train\n",
    "#df_default_train = df_analyze[X_train.index][\"uuid\", \"default\"]\n",
    "df_default_train = df_analyze[df_analyze.index.isin(X_train.index.to_list())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_default_train.sort_index(inplace=True)\n",
    "X_train.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "y_predict_proba_train = CV_clf_rf.predict_proba(X_train)[:, 1]\n",
    "yhat_predict_train = CV_clf_rf.predict(X_train)\n",
    "\n",
    "# Calibrated Random Forest\n",
    "y_predict_proba_crf_train = clf_sigmoid.predict_proba(X_train)[:, 1]\n",
    "yhat_predict_crf_train = clf_sigmoid.predict(X_train)\n",
    "\n",
    "#NB\n",
    "\n",
    "y_predict_nb_train = clf_nb.predict_proba(X_train)[:, 1]\n",
    "yhat_predict_nb_train = clf_nb.predict(X_train)\n",
    "\n",
    "# Isotonic\n",
    "y_predict_nb_isotonic_train = clf_sigmoid_nb.predict_proba(X_train)[:, 1]\n",
    "yhat_predict_isotonic_train = clf_sigmoid_nb.predict(X_train)\n",
    "\n",
    "# Sigmoid\n",
    "y_predict_nb_sigmoid_train = clf_sigmoid_nb_calib_sig.predict_proba(X_train)[:, 1]\n",
    "yhat_predict_sigmoid_train = clf_sigmoid_nb_calib_sig.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_rf_nb = pd.concat([df_default_train[[\"uuid\", \"default\"]].reset_index(drop=True), \n",
    "           pd.Series(y_predict_proba_train, name=\"Random Forest Probability\").reset_index(drop=True),\n",
    "           pd.Series(y_predict_proba_crf_train, name=\"Calibrated Random Forest Probability\").reset_index(drop=True),\n",
    "           pd.Series(y_predict_nb_train, name=\"Naive Bayes\").reset_index(drop=True), \n",
    "           pd.Series(y_predict_nb_isotonic_train, name=\"Calibrated Naive Bayes (Isotonic)\").reset_index(drop=True),\n",
    "           pd.Series(y_predict_nb_sigmoid_train, name=\"Calibrated Naive Bayes (Sigmoid)\").reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_analyze_train\n",
    "#df_default_train = df_analyze[X_train.index][\"uuid\", \"default\"]\n",
    "df_default_test = df_analyze[df_analyze.index.isin(X_test.index.to_list())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_default_test.sort_index(inplace=True)\n",
    "X_test.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "y_predict_proba_test = CV_clf_rf.predict_proba(X_test)[:, 1]\n",
    "yhat_predict_test = CV_clf_rf.predict(X_test)\n",
    "\n",
    "# Calibrated Random Forest\n",
    "y_predict_proba_crf_test = clf_sigmoid.predict_proba(X_test)[:, 1]\n",
    "yhat_predict_crf_test = clf_sigmoid.predict(X_test)\n",
    "\n",
    "#NB\n",
    "\n",
    "y_predict_nb_test = clf_nb.predict_proba(X_test)[:, 1]\n",
    "yhat_predict_nb_test = clf_nb.predict(X_test)\n",
    "\n",
    "# Isotonic\n",
    "y_predict_nb_isotonic_test = clf_sigmoid_nb.predict_proba(X_test)[:, 1]\n",
    "yhat_predict_isotonic_test = clf_sigmoid_nb.predict(X_test)\n",
    "\n",
    "# Sigmoid\n",
    "y_predict_nb_sigmoid_test = clf_sigmoid_nb_calib_sig.predict_proba(X_test)[:, 1]\n",
    "yhat_predict_sigmoid_test = clf_sigmoid_nb_calib_sig.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_rf_nb = pd.concat([df_default_test[[\"uuid\", \"default\"]].reset_index(drop=True), \n",
    "                          pd.Series(y_predict_proba_test, name=\"Random Forest Probability\").reset_index(drop=True),\n",
    "                          pd.Series(y_predict_proba_crf_test, name=\"Calibrated Random Forest Probability\").reset_index(drop=True),\n",
    "                          pd.Series(y_predict_nb_test, name=\"Naive Bayes\").reset_index(drop=True),\n",
    "                          pd.Series(y_predict_nb_isotonic_test, name=\"Calibrated Naive Bayes (Isotonic)\").reset_index(drop=True),\n",
    "                          pd.Series(y_predict_nb_sigmoid_test, name=\"Calibrated Naive Bayes (Sigmoid)\").reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concat all results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_results = pd.concat([nan_df_rf_nb, train_df_rf_nb, test_df_rf_nb], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstart = time.time()\\n#hyper_svm = {\"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\\n#           \"C\": [1, 100, 1000],\\n#           \"gamma\": [1, 0.1, 0.00001]}\\n\\n\\nhyper_svm = {\"kernel\": [\"rbf\"],\\n           \"C\": [1],\\n           \"gamma\": [1]}\\nclf_svm_tuned = GridSearchCV(SVC(probability=True), \\n                             hyper_svm,\\n                             cv=3,\\n                             verbose=1,\\n                             n_jobs=6)\\n\\nclf_svm_tuned.fit(os_data_X, os_data_y)\\nbest_params_svm = clf_svm_tuned.best_params_\\nprint(best_params_svm)\\n\\n\\nCV_clf_svm = SVC(kernel=best_params_svm[\"kernel\"],\\n                 C=best_params_svm[\"C\"],\\n                 gamma=best_params_svm[\"gamma\"],\\n                 probability=True)\\n\\nCV_clf_svm.fit(os_data_X, os_data_y)\\ny_test_predict_proba_svm = CV_clf_svm.predict_proba(X_test)[:, 1]\\nyhat_svm = CV_clf_svm.predict(X_test)\\nfraction_of_positives_svm, mean_predicted_value_svm = calibration_curve(y_test, y_test_predict_proba_svm, n_bins=10)\\n\\n\\nend = time.time()\\nhours, rem = divmod(end-start, 3600)\\nminutes, seconds = divmod(rem, 60)\\nprint(\"\\nÇalışma süresi: \"+\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "start = time.time()\n",
    "#hyper_svm = {\"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "#           \"C\": [1, 100, 1000],\n",
    "#           \"gamma\": [1, 0.1, 0.00001]}\n",
    "\n",
    "\n",
    "hyper_svm = {\"kernel\": [\"rbf\"],\n",
    "           \"C\": [1],\n",
    "           \"gamma\": [1]}\n",
    "clf_svm_tuned = GridSearchCV(SVC(probability=True), \n",
    "                             hyper_svm,\n",
    "                             cv=3,\n",
    "                             verbose=1,\n",
    "                             n_jobs=6)\n",
    "\n",
    "clf_svm_tuned.fit(os_data_X, os_data_y)\n",
    "best_params_svm = clf_svm_tuned.best_params_\n",
    "print(best_params_svm)\n",
    "\n",
    "\n",
    "CV_clf_svm = SVC(kernel=best_params_svm[\"kernel\"],\n",
    "                 C=best_params_svm[\"C\"],\n",
    "                 gamma=best_params_svm[\"gamma\"],\n",
    "                 probability=True)\n",
    "\n",
    "CV_clf_svm.fit(os_data_X, os_data_y)\n",
    "y_test_predict_proba_svm = CV_clf_svm.predict_proba(X_test)[:, 1]\n",
    "yhat_svm = CV_clf_svm.predict(X_test)\n",
    "fraction_of_positives_svm, mean_predicted_value_svm = calibration_curve(y_test, y_test_predict_proba_svm, n_bins=10)\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "hours, rem = divmod(end-start, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print(\"\\nÇalışma süresi: \"+\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstart = time.time()\\n# Create a corrected classifier.\\nclf_sigmoid_svm = CalibratedClassifierCV(CV_clf_svm, cv=10, method=\\'sigmoid\\')\\nclf_sigmoid_svm.fit(os_data_X, os_data_y)\\ny_test_predict_proba_svm_calibrated = clf_sigmoid_svm.predict_proba(X_test)[:, 1]\\nyhat_calibrated_svm = clf_sigmoid_svm.predict(X_test)\\nfraction_of_positives_svm_calibrated, mean_predicted_value_svm_calibrated = calibration_curve(y_test, y_test_predict_proba_svm_calibrated, n_bins=10)\\n\\n#plt.plot(mean_predicted_value, fraction_of_positives, \\'s-\\', label=\\'Calibrated (Platt)\\')\\n#plt.plot([0, 1], [0, 1], \\'--\\', color=\\'gray\\')\\n\\n#sns.despine(left=True, bottom=True)\\n#plt.gca().xaxis.set_ticks_position(\\'none\\')\\n#plt.gca().yaxis.set_ticks_position(\\'none\\')\\n#plt.gca().legend()\\n#plt.title(\"$SVM$ Sample Calibration Curve\", fontsize=20); pass\\n\\nend = time.time()\\nhours, rem = divmod(end-start, 3600)\\nminutes, seconds = divmod(rem, 60)\\nprint(\"\\nÇalışma süresi: \"+\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "start = time.time()\n",
    "# Create a corrected classifier.\n",
    "clf_sigmoid_svm = CalibratedClassifierCV(CV_clf_svm, cv=10, method='sigmoid')\n",
    "clf_sigmoid_svm.fit(os_data_X, os_data_y)\n",
    "y_test_predict_proba_svm_calibrated = clf_sigmoid_svm.predict_proba(X_test)[:, 1]\n",
    "yhat_calibrated_svm = clf_sigmoid_svm.predict(X_test)\n",
    "fraction_of_positives_svm_calibrated, mean_predicted_value_svm_calibrated = calibration_curve(y_test, y_test_predict_proba_svm_calibrated, n_bins=10)\n",
    "\n",
    "#plt.plot(mean_predicted_value, fraction_of_positives, 's-', label='Calibrated (Platt)')\n",
    "#plt.plot([0, 1], [0, 1], '--', color='gray')\n",
    "\n",
    "#sns.despine(left=True, bottom=True)\n",
    "#plt.gca().xaxis.set_ticks_position('none')\n",
    "#plt.gca().yaxis.set_ticks_position('none')\n",
    "#plt.gca().legend()\n",
    "#plt.title(\"$SVM$ Sample Calibration Curve\", fontsize=20); pass\n",
    "\n",
    "end = time.time()\n",
    "hours, rem = divmod(end-start, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print(\"\\nÇalışma süresi: \"+\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclassification_report(y_test, yhat_svm)\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "classification_report(y_test, yhat_svm)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrated SVM Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclassification_report(y_test, yhat_calibrated_svm)\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "classification_report(y_test, yhat_calibrated_svm)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_results.to_csv(\"../data/Probability_All_Results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Table '../data/df_all_results' already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-ea12d22c90bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"df_all_results.db\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_all_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../data/df_all_results\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   2603\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msql\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2605\u001b[1;33m         sql.to_sql(\n\u001b[0m\u001b[0;32m   2606\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2607\u001b[0m             \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m    587\u001b[0m         )\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m     pandas_sql.to_sql(\n\u001b[0m\u001b[0;32m    590\u001b[0m         \u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   1825\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1826\u001b[0m         )\n\u001b[1;32m-> 1827\u001b[1;33m         \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1828\u001b[0m         \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1829\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mif_exists\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"fail\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 723\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Table '{self.name}' already exists.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    724\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mif_exists\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    725\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpd_sql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Table '../data/df_all_results' already exists."
     ]
    }
   ],
   "source": [
    "conn = sql.connect(\"df_all_results.db\")\n",
    "df_all_results.to_sql(\"../data/df_all_results\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
